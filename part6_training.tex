%==============================================================================
% PART 6: TRAINING PIPELINE
%==============================================================================

\section{Training Pipeline}

%------------------------------------------------------------------------------
\begin{frame}{Three-Stage Training}
    \begin{center}
    \begin{tikzpicture}[
        stage/.style={rectangle, draw, rounded corners, minimum width=2.8cm, minimum height=1.8cm, align=center, font=\small},
        arrow/.style={->, thick, >=stealth}
    ]
        \node[stage, fill=vqpurple!30] (s1) at (0,0) {\textbf{Stage 1}\\VQ Training\\{\scriptsize (Action Tokenizer)}};
        \node[stage, fill=rdtgreen!30] (s2) at (4.5,0) {\textbf{Stage 2}\\FM Training\\{\scriptsize (Action Expert)}};
        \node[stage, fill=actionorange!30] (s3) at (9,0) {\textbf{Stage 3}\\Distillation\\{\scriptsize (UltraFast)}};

        \draw[arrow] (s1) -- (s2);
        \draw[arrow] (s2) -- (s3);

        \node[below=0.15cm, font=\footnotesize] at (s1.south) {RDT2-VQ};
        \node[below=0.15cm, font=\footnotesize] at (s2.south) {RDT2-FM};
        \node[below=0.15cm, font=\footnotesize] at (s3.south) {Coming Soon};
    \end{tikzpicture}
    \end{center}

    \vspace{0.5cm}
    \textbf{Stage 1:} Train VLA with VQVAE action tokenizer \\
    \textbf{Stage 2:} Train RDT action expert with frozen VLM \\
    \textbf{Stage 3:} Distill to single-step model (future)
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Training Entry Points}
    \textbf{Key Files:}

    \vspace{0.5cm}
    \begin{table}
        \centering
        \renewcommand{\arraystretch}{1.3}
        \begin{tabular}{lll}
            \toprule
            \textbf{Stage} & \textbf{Entry Point} & \textbf{Purpose} \\
            \midrule
            Stage 1 (VQ) & \code{main.py} & VLA fine-tuning \\
            Stage 1 (VQ) & \code{train.py} & Core training loop \\
            Stage 2 (FM) & \code{rdt/main.py} & RDT training entry \\
            Stage 2 (FM) & \code{rdt/train.py} & RDT training loop \\
            \bottomrule
        \end{tabular}
    \end{table}

    \vspace{0.5cm}
    \textbf{Training Scripts:}
    \begin{itemize}
        \item \code{scripts/finetune\_lora.sh} - LoRA ($\sim$32GB)
        \item \code{scripts/finetune\_full\_param.sh} - Full ($\sim$80GB)
        \item \code{scripts/finetune\_rdt.sh} - RDT only ($\sim$16GB)
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Stage 1: VLA Training Overview}
    \begin{center}
    \begin{tikzpicture}[
        box/.style={rectangle, draw, rounded corners, minimum width=2cm, minimum height=0.7cm, align=center, font=\scriptsize},
        arrow/.style={->, thick},
        scale=0.75, transform shape
    ]
        % Data
        \node[box, fill=blue!20] (data) at (0,3) {WebDataset\\TAR shards};

        % Processing
        \node[box, fill=gray!30] (load) at (0,1.5) {Data Loading\\+ Augmentation};
        \node[box, fill=yellow!30] (vae) at (0,0) {VQVAE\\Encode};

        % Model
        \node[box, fill=qwenblue!30, minimum width=4cm] (qwen) at (5,1.5) {Qwen2.5-VL-7B\\(Full/LoRA/QLoRA)};

        % Loss
        \node[box, fill=red!30] (loss) at (5,0) {Cross-Entropy\\Loss};

        % Trainer
        \node[box, fill=rdtgreen!30] (trainer) at (10,1.5) {HuggingFace\\Trainer};

        % Arrows
        \draw[arrow] (data) -- (load);
        \draw[arrow] (load) -- (vae);
        \draw[arrow] (load) -- (qwen);
        \draw[arrow] (vae) -- node[above, font=\tiny] {labels} (loss);
        \draw[arrow] (qwen) -- node[left, font=\tiny] {logits} (loss);
        \draw[arrow] (loss) -- (trainer);
        \draw[arrow] (trainer) -- ++(0,1) -| (qwen);
    \end{tikzpicture}
    \end{center}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{main.py: Command-Line Arguments}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{Model:}
            \begin{lstlisting}[language=Python]
--pretrained_model_name_or_path
--vae_name
--output_dir
            \end{lstlisting}

            \textbf{Training:}
            \begin{lstlisting}[language=Python]
--train_batch_size 4
--learning_rate 5e-6
--lr_warmup_steps 500
            \end{lstlisting}
        \end{column}
        \begin{column}{0.5\textwidth}
            \textbf{LoRA:}
            \begin{lstlisting}[language=Python]
--use_lora False
--use_qlora False
--lora_r 8
--lora_alpha 8
--lora_dropout 0.1
            \end{lstlisting}
        \end{column}
    \end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{train.py: Core Training Loop}
    \textbf{1. Model Loading:}
    \begin{lstlisting}[language=Python]
# Load Vision-Language Model
model = Qwen2_5_VLForConditionalGeneration \
    .from_pretrained(
        args.pretrained_model_name_or_path,
        torch_dtype=weight_dtype,
        attn_implementation="flash_attention_2"
    )

# Load Action Tokenizer
vae = MultiVQVAE.from_pretrained(args.vae_name)
vae = vae.to("cuda").float()
    \end{lstlisting}

    \vspace{0.3cm}
    \textbf{2. LoRA Setup (if enabled):}
    \begin{lstlisting}[language=Python]
if args.use_lora:
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Collate Function (1/2)}
    \textbf{Prepare batch for training:}

    \vspace{0.3cm}
    \begin{lstlisting}[language=Python]
def collate_fn(examples):
    # 1. Process images
    images = [preprocess_image(ex["image"]) for ex in examples]

    # 2. Encode actions to tokens
    actions = torch.stack([ex["action"] for ex in examples])
    action_tokens = vae.encode(actions)  # [B, 27]

    # 3. Convert to VLA token IDs
    vla_tokens = vocab_size - action_tokens - 1
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Collate Function (2/2)}
    \textbf{Continue batch preparation:}

    \vspace{0.3cm}
    \begin{lstlisting}[language=Python]
    # 4. Build chat template
    messages = build_chat_messages(images, instructions)
    inputs = processor(messages)

    # 5. Insert action tokens into labels
    labels = inputs["input_ids"].clone()
    labels[~action_mask] = -100  # Ignore non-action

    return {"input_ids": ..., "labels": labels, ...}
    \end{lstlisting}

    \vspace{0.3cm}
    \begin{block}{Key Points}
        \begin{itemize}
            \item VQVAE encodes actions to 27 discrete tokens
            \item Only action tokens contribute to loss (label mask)
        \end{itemize}
    \end{block}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Training Arguments}
    \begin{lstlisting}[language=Python]
TrainingArguments(
    output_dir=args.output_dir,
    per_device_train_batch_size=args.train_batch_size,
    per_device_eval_batch_size=args.eval_batch_size,
    learning_rate=args.learning_rate,
    max_steps=args.max_train_steps,
    bf16=True,  # Mixed precision
    deepspeed=args.deepspeed,  # DeepSpeed config
    gradient_checkpointing=args.gradient_checkpointing,
    gradient_accumulation_steps=
        args.gradient_accumulation_steps,
    save_steps=args.checkpointing_steps,
    save_total_limit=args.checkpoints_total_limit,
    logging_steps=10,
    dataloader_num_workers=16,
    dataloader_pin_memory=True,
)
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{DeepSpeed ZeRO-1 Configuration}
    \textbf{File:} \code{scripts/zero1.json}

    \vspace{0.3cm}
    \begin{lstlisting}[language=Python]
{
    "bf16": {"enabled": "auto"},
    "train_micro_batch_size_per_gpu": "auto",
    "train_batch_size": "auto",
    "gradient_accumulation_steps": "auto",
    "zero_optimization": {
        "stage": 1,
        "allgather_partitions": true,
        "allgather_bucket_size": 5e8,
        "overlap_comm": true,
        "contiguous_gradients": true,
        "reduce_bucket_size": 8e8
    },
    "gradient_clipping": "auto"
}
    \end{lstlisting}

    \vspace{0.3cm}
    \textbf{ZeRO Stage 1:} Optimizer state partitioning only
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{VLATrainer: Custom Evaluation}
    \begin{columns}[T]
        \begin{column}{0.55\textwidth}
            \textbf{File:} \code{vla\_trainer.py}
            \begin{lstlisting}[language=Python]
class VLATrainer(Trainer):
    def __init__(self, num_eval_datasets=2,
                 num_eval_batches=4, **kwargs):
        super().__init__(**kwargs)
        ...

    def evaluation_loop(self, ...):
        # Custom metrics computation
        ...
            \end{lstlisting}
        \end{column}
        \begin{column}{0.45\textwidth}
            \textbf{Features:}
            \begin{itemize}
                \item Multi-dataset eval
                \item Limited batch eval
                \item Custom metrics:
                \begin{itemize}
                    \item valid\_rate
                    \item mse\_error
                    \item geodesic
                \end{itemize}
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Evaluation Metrics Computation}
    \begin{lstlisting}[language=Python]
def compute_action_metrics(pred_action, gt_action):
    # 1. Valid rate
    valid_mask = (pred_tokens >= 0) & (pred_tokens < 1024)
    valid_rate = valid_mask.float().mean()

    # 2. MSE (total)
    mse_error = F.mse_loss(pred_action, gt_action)

    # 3. MSE (position) - indices [0:3, 10:13]
    mse_pos = F.mse_loss(pred_action[..., pos_idx],
                         gt_action[..., pos_idx])

    # 4. Geodesic (rotation) - indices [3:9, 13:19]
    R_pred = rot6d_to_matrix(pred_action[..., rot_idx])
    R_gt = rot6d_to_matrix(gt_action[..., rot_idx])
    geodesic = compute_geodesic_distance(R_pred, R_gt)

    # 5. MSE (gripper) - indices [9, 19]
    mse_grip = F.mse_loss(pred_action[..., grip_idx],
                          gt_action[..., grip_idx])
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Stage 2: RDT Training Overview}
    \begin{center}
    \begin{tikzpicture}[
        box/.style={rectangle, draw, rounded corners, minimum width=2.2cm, minimum height=0.9cm, align=center, font=\small},
        arrow/.style={->, thick, >=stealth},
        scale=0.85, transform shape
    ]
        % Row 1: Data source
        \node[box, fill=blue!20] (data) at (0,3) {WebDataset\\TAR shards};

        % Row 2: Data loading and VLM
        \node[box, fill=gray!30] (load) at (0,1) {Data Loading};
        \node[box, fill=qwenblue!30] (qwen) at (4.5,3) {Qwen2.5-VL\\(Frozen)};
        \node[box, fill=yellow!30] (kv) at (4.5,1) {KV Cache};

        % Row 3: RDT Expert
        \node[box, fill=rdtgreen!30] (rdt) at (9,1) {RDT Expert\\(Trainable)};

        % Row 4: Loss
        \node[box, fill=red!30] (loss) at (9,-1) {Flow Matching\\Loss};

        % Ground truth actions
        \node[box, fill=actionorange!30] (gt) at (4.5,-1) {GT Actions};

        % Arrows - Data flow
        \draw[arrow] (data) -- (load);
        \draw[arrow] (load) -- node[above, font=\scriptsize] {images} (qwen);
        \draw[arrow] (qwen) -- (kv);
        \draw[arrow] (kv) -- (rdt);

        % Actions arrow - goes below to avoid collision
        \draw[arrow] (load.south) -- ++(0,-0.5) -| node[below, font=\scriptsize, pos=0.25] {actions} (gt.west);
        \draw[arrow] (gt) -- (loss);

        % RDT to Loss
        \draw[arrow] (rdt) -- node[right, font=\scriptsize] {pred} (loss);

        % Gradient flow (backprop) - dashed
        \draw[arrow, dashed, red!70] (loss.north east) -- ++(0.8,0) |- node[right, font=\scriptsize, pos=0.25] {grad} (rdt.east);

        % Frozen indicator
        \node[draw, dashed, blue, thick, fit=(qwen), inner sep=3pt, label={[font=\tiny, blue]above right:Frozen}] {};

        % Trainable indicator
        \node[draw, dashed, rdtgreen, thick, fit=(rdt), inner sep=3pt, label={[font=\tiny, rdtgreen]above right:Trainable}] {};
    \end{tikzpicture}
    \end{center}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{rdt/main.py: Arguments}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{Model:}
            \begin{lstlisting}[language=Python]
--config_path
--pretrained_vlm_path
--webdataset_config
            \end{lstlisting}

            \textbf{Training:}
            \begin{lstlisting}[language=Python]
--train_batch_size 256
--max_train_steps 1M
--learning_rate 1e-4
            \end{lstlisting}
        \end{column}
        \begin{column}{0.5\textwidth}
            \textbf{Augmentation:}
            \begin{lstlisting}[language=Python]
--image_aug False
--cond_mask_prob 0.1
--cam_ext_mask_prob 0.2
--state_noise_snr 40
            \end{lstlisting}
        \end{column}
    \end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{rdt/train.py: Training Loop}
    \begin{lstlisting}[language=Python]
for step in range(args.max_train_steps):
    batch = next(train_dataloader)

    # 1. Normalize actions
    naction = normalizer["action"].normalize(batch["actions"])

    # 2. Extract VLM features (frozen)
    with torch.no_grad():
        kv_cache = extract_kv_cache(vlm, batch)

    # 3. RDT forward (flow-matching loss)
    loss = rdt_runner(naction, batch["states"], kv_cache, ...)

    # 4. Backward + optimize
    accelerator.backward(loss)
    optimizer.step(); lr_scheduler.step(); optimizer.zero_grad()
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Dataset Configuration (1/2)}
    \textbf{File:} \code{configs/datasets/example.yaml}

    \vspace{0.3cm}
    \textbf{Single Dataset:}
    \begin{lstlisting}[language=Python]
name: bimanual/ur_example
type: single
shards_dir: /path/to/shards
kwargs:
  instruction_path: /path/to/instruction.json
  normalizer_path: /path/to/normalizer.pt
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Dataset Configuration (2/2)}
    \textbf{Blended Dataset:}
    \begin{lstlisting}[language=Python]
name: blended_dataset
type: blended
datasets:
  - name: dataset1
    weight: 0.5
    config_path: configs/datasets/dataset1.yaml
  - name: dataset2
    weight: 0.5
    config_path: configs/datasets/dataset2.yaml
    \end{lstlisting}

    \vspace{0.5cm}
    \begin{block}{Dataset Blending}
        Multiple datasets can be combined with different weights for diverse training data
    \end{block}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{WebDataset Loading (1/2)}
    \textbf{File:} \code{rdt/dataset.py}

    \vspace{0.3cm}
    \begin{lstlisting}[language=Python]
def get_train_dataset(shards_dir):
    # Load TAR shards
    dataset = wds.WebDataset(shards_dir)
    dataset = dataset.shuffle(1000)
    dataset = dataset.decode("pil")

    # Map to dictionary
    dataset = dataset.map(lambda x: {
        "image": x["image.jpg"],
        "action": np.load(io.BytesIO(x["action.npy"])),
        "meta": json.loads(x["meta.json"])
    })
    return dataset
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{WebDataset Loading (2/2)}
    \textbf{Multi-Dataset Blending:}
    \begin{lstlisting}[language=Python]
dataset = wds.RandomMix(datasets, weights)
    \end{lstlisting}

    \vspace{0.5cm}
    \begin{block}{WebDataset Benefits}
        \begin{itemize}
            \item Streaming from TAR archives (no extraction)
            \item Built-in shuffling and parallel loading
            \item Supports distributed training
        \end{itemize}
    \end{block}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Normalizer (1/2)}
    \textbf{File:} \code{models/normalizer/normalizer.py}

    \vspace{0.3cm}
    \textbf{Normalization Modes:}
    \begin{itemize}
        \item \code{"limits"}: Min-max $\rightarrow [-1, 1]$
        \item \code{"gaussian"}: Standardization $\rightarrow \mu=0, \sigma=1$
    \end{itemize}

    \vspace{0.3cm}
    \begin{lstlisting}[language=Python]
# Forward normalization
x_norm = x * scale + offset

# Inverse normalization
x_orig = (x - offset) / scale
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Normalizer (2/2)}
    \begin{lstlisting}[language=Python]
# Field-specific access
normalizer["action"].normalize(action)
normalizer["action"].unnormalize(action)

# Save/Load
normalizer.save("normalizer.pt")
normalizer = LinearNormalizer.load("normalizer.pt")
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Training Script: LoRA}
    \textbf{File:} \code{scripts/finetune\_lora.sh}

    \vspace{0.3cm}
    \begin{lstlisting}[language=bash]
accelerate launch --config_file scripts/zero1.json main.py \
    --pretrained_model_name_or_path \
        robotics-diffusion-transformer/RDT2-VQ \
    --vae_name \
        robotics-diffusion-transformer/RVQActionTokenizer \
    --dataset configs/datasets/your_dataset.yaml \
    --output_dir outputs/lora_finetune \
    --train_batch_size 96 \
    --max_train_steps 10000 \
    --learning_rate 1e-4 \
    --lr_scheduler cosine \
    --mixed_precision bf16 \
    --use_lora \
    --gradient_checkpointing \
    --checkpointing_steps 1000 \
    --dataloader_num_workers 16
    \end{lstlisting}

    \vspace{0.3cm}
    \textbf{VRAM:} $\sim$32 GB
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Training Script: Full Parameter}
    \textbf{File:} \code{scripts/finetune\_full\_param.sh}

    \vspace{0.3cm}
    \begin{lstlisting}[language=bash]
accelerate launch --config_file scripts/zero1.json main.py \
    --pretrained_model_name_or_path \
        robotics-diffusion-transformer/RDT2-VQ \
    --vae_name \
        robotics-diffusion-transformer/RVQActionTokenizer \
    --dataset configs/datasets/your_dataset.yaml \
    --output_dir outputs/full_finetune \
    --train_batch_size 64 \
    --max_train_steps 10000 \
    --learning_rate 1e-5 \
    --lr_scheduler cosine \
    --mixed_precision bf16 \
    --gradient_checkpointing \
    --checkpointing_steps 1000 \
    --dataloader_num_workers 16
    \end{lstlisting}

    \vspace{0.3cm}
    \textbf{VRAM:} $\sim$80 GB (A100 80GB / H100)
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Training Script: RDT Only}
    \textbf{File:} \code{scripts/finetune\_rdt.sh}

    \vspace{0.3cm}
    \begin{lstlisting}[language=bash]
accelerate launch --config_file scripts/zero1.json \
    rdt/main.py \
    --pretrained_vision_language_model_name_or_path \
        robotics-diffusion-transformer/RDT2-VQ \
    --config_path configs/rdt/post_train.yaml \
    --webdataset_config configs/datasets/your_dataset.yaml \
    --output_dir outputs/rdt_finetune \
    --train_batch_size 64 \
    --sample_batch_size 32 \
    --max_train_steps 1000000 \
    --learning_rate 1e-4 \
    --checkpointing_period 5000 \
    --sample_period 1000 \
    --image_aug
    \end{lstlisting}

    \vspace{0.3cm}
    \textbf{VRAM:} $\sim$16 GB (RTX 4090)
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{VRAM Requirements Summary}
    \begin{table}
        \centering
        \renewcommand{\arraystretch}{1.4}
        \begin{tabular}{lccc}
            \toprule
            \textbf{Training Mode} & \textbf{VRAM} & \textbf{GPU Example} & \textbf{Params} \\
            \midrule
            Full Fine-tune & $\geq$80 GB & A100 80GB / H100 & 7B \\
            LoRA & $\geq$32 GB & A100 40GB & $\sim$20M \\
            QLoRA & $\geq$20 GB & RTX 4090 & $\sim$20M \\
            RDT Only & $\sim$16 GB & RTX 4090 & 400M \\
            Inference & $\sim$16 GB & RTX 4090 & -- \\
            \bottomrule
        \end{tabular}
    \end{table}

    \vspace{0.5cm}
    \begin{alertblock}{Recommendation}
        For most use cases, \textbf{RDT-only training} ($\sim$16GB) provides good results with minimal hardware requirements
    \end{alertblock}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Training Tips}
    \textbf{1. Learning Rate:}
    \begin{itemize}
        \item Full fine-tune: $1 \times 10^{-5}$
        \item LoRA: $1 \times 10^{-4}$
        \item RDT: $1 \times 10^{-4}$
    \end{itemize}

    \vspace{0.3cm}
    \textbf{2. Batch Size:}
    \begin{itemize}
        \item Larger is better for RDT (256+ recommended)
        \item Use gradient accumulation if limited VRAM
    \end{itemize}

    \vspace{0.3cm}
    \textbf{3. Gradient Checkpointing:}
    \begin{itemize}
        \item Enable for large models (\code{--gradient\_checkpointing})
        \item Trades compute for memory
    \end{itemize}

    \vspace{0.3cm}
    \textbf{4. Mixed Precision:}
    \begin{itemize}
        \item Always use \code{bf16} on modern GPUs
        \item Better numerical stability than \code{fp16}
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}[fragile]{Checkpointing}
    \textbf{Checkpoint Contents:}

    \vspace{0.3cm}
    \begin{itemize}
        \item \code{model.safetensors} - Model weights
        \item \code{optimizer.pt} - Optimizer state
        \item \code{scheduler.pt} - LR scheduler state
        \item \code{trainer\_state.json} - Training metadata
        \item \code{config.json} - Model configuration
    \end{itemize}

    \vspace{0.5cm}
    \textbf{Checkpoint Management:}
    \begin{lstlisting}[language=Python]
--checkpointing_steps 1000      # Save every N steps
--checkpoints_total_limit 20    # Keep last N checkpoints
    \end{lstlisting}

    \vspace{0.3cm}
    \textbf{Resume Training:}
    \begin{lstlisting}[language=Python]
--resume_from_checkpoint path/to/checkpoint
    \end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Training Monitoring (1/2)}
    \textbf{Logged Metrics:}

    \vspace{0.3cm}
    \begin{table}
        \centering
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{ll}
            \toprule
            \textbf{Metric} & \textbf{Description} \\
            \midrule
            \code{train/loss} & Training loss \\
            \code{train/learning\_rate} & Current LR \\
            \code{eval/valid\_rate} & Valid token ratio \\
            \code{eval/mse\_error} & Total MSE \\
            \bottomrule
        \end{tabular}
    \end{table}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Training Monitoring (2/2)}
    \textbf{Additional Metrics:}
    \begin{table}
        \centering
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{ll}
            \toprule
            \textbf{Metric} & \textbf{Description} \\
            \midrule
            \code{eval/mse\_error\_pos} & Position MSE \\
            \code{eval/geodesic\_error\_rot} & Rotation error \\
            \code{eval/mse\_error\_width} & Gripper MSE \\
            \bottomrule
        \end{tabular}
    \end{table}

    \vspace{0.3cm}
    \textbf{Visualization:}
    \begin{itemize}
        \item TensorBoard: \code{tensorboard --logdir outputs/}
        \item Weights \& Biases: \code{--report\_to wandb}
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Training Pipeline Summary}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{Stage 1 (VQ):}
            \begin{itemize}
                \item Entry: \code{main.py}
                \item Model: Qwen2.5-VL
                \item Loss: Cross-entropy
                \item Output: Discrete tokens
                \item Fine-tune: Full/LoRA/QLoRA
            \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \textbf{Stage 2 (FM):}
            \begin{itemize}
                \item Entry: \code{rdt/main.py}
                \item Model: RDT Expert
                \item Loss: Flow matching
                \item Output: Continuous
                \item VLM: Frozen
            \end{itemize}
        \end{column}
    \end{columns}

    \vspace{0.5cm}
    \begin{block}{Key Files}
        \begin{itemize}
            \item \code{train.py}, \code{rdt/train.py} - Core training
            \item \code{vla\_trainer.py} - Custom evaluation
            \item \code{scripts/zero1.json} - DeepSpeed config
            \item \code{configs/datasets/*.yaml} - Dataset configs
        \end{itemize}
    \end{block}
\end{frame}

