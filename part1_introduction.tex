%==============================================================================
% PART 1: INTRODUCTION
%==============================================================================

\section{Introduction}

%------------------------------------------------------------------------------
\begin{frame}{What is RDT2?}
    \begin{block}{Definition}
        \textbf{RDT2} = \textbf{R}obotics \textbf{D}iffusion \textbf{T}ransformer \textbf{2}
    \end{block}

    \vspace{0.5cm}
    \textbf{Core Innovation:}
    \begin{itemize}
        \item First foundation model for \textbf{zero-shot cross-embodiment} deployment
        \item Works on \textbf{unseen robots} without fine-tuning
        \item Trained on 10,000+ hours of bimanual manipulation data
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Supported Tasks}
    \textbf{Open-vocabulary manipulation tasks:}

    \vspace{0.5cm}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \begin{itemize}
                \item Picking objects
                \item Placing objects
                \item Pressing buttons
                \item Wiping surfaces
            \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{itemize}
                \item Folding fabric
                \item Table setting
                \item Archery interception
                \item General manipulation
            \end{itemize}
        \end{column}
    \end{columns}

    \vspace{0.5cm}
    \begin{alertblock}{Reaction Time}
        Archery interception achieved $\sim$100ms reaction time (human-level)
    \end{alertblock}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Supported Robot Platforms}
    \textbf{Zero-shot deployment (no fine-tuning required):}

    \vspace{0.8cm}
    \begin{columns}[T]
        \begin{column}{0.45\textwidth}
            \centering
            \textbf{\large UR5e}

            \vspace{0.3cm}
            \begin{itemize}
                \item Universal Robots
                \item 6-DoF industrial arm
                \item RTDE protocol (125-500 Hz)
            \end{itemize}
        \end{column}
        \begin{column}{0.45\textwidth}
            \centering
            \textbf{\large Franka FR3}

            \vspace{0.3cm}
            \begin{itemize}
                \item Franka Emika
                \item 7-DoF research arm
                \item Torque control (1000 Hz)
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Three Pillars of RDT2}
    \begin{enumerate}
        \item \textbf{Redesigned UMI Hardware}
              \begin{itemize}
                  \item Nylon 66 + Glass fiber (CNC machined)
                  \item HTC VIVE Tracker 3.0 for 6DoF tracking
              \end{itemize}

              \vspace{0.4cm}
        \item \textbf{Massive Diverse Dataset}
              \begin{itemize}
                  \item 10,000+ hours of manipulation video
                  \item 100+ real-world home/office environments
              \end{itemize}

              \vspace{0.4cm}
        \item \textbf{3-Stage Training Pipeline}
              \begin{itemize}
                  \item Stage 1: VQ (action tokenization)
                  \item Stage 2: FM (flow-matching)
                  \item Stage 3: Distillation (coming soon)
              \end{itemize}
    \end{enumerate}
\end{frame}

%==============================================================================
\section{Model Variants}

%------------------------------------------------------------------------------
\begin{frame}{Overview: Three Model Variants}
    \begin{table}
        \centering
        \renewcommand{\arraystretch}{1.3}
        \begin{tabular}{lccc}
            \toprule
            & \textbf{RDT2-VQ} & \textbf{RDT2-FM} & \textbf{RDT2-UltraFast} \\
            \midrule
            Stage           & 1            & 2            & 3               \\
            Output Type     & Discrete     & Continuous   & Continuous      \\
            Forward Passes  & 27           & 6            & 2               \\
            Status          & \cmark       & \cmark       & Coming Soon     \\
            \bottomrule
        \end{tabular}
    \end{table}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{RDT2-VQ: Stage 1}
    \begin{block}{Architecture}
        Fine-tuned \textbf{Qwen2.5-VL-7B-Instruct} + RVQ Action Tokenizer
    \end{block}

    \vspace{0.5cm}
    \textbf{Input:}
    \begin{itemize}
        \item 2 wrist-camera fisheye images ($384 \times 384$ each)
        \item Language instruction (e.g., "Pick up the apple.")
    \end{itemize}

    \vspace{0.3cm}
    \textbf{Output:}
    \begin{itemize}
        \item 27 discrete action tokens (autoregressive generation)
        \item Decoded to continuous actions via VQVAE
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{RDT2-VQ: Key Properties}
    \textbf{Inference Process:}
    \begin{itemize}
        \item 27 forward passes (one per token)
        \item Autoregressive: each token depends on previous
    \end{itemize}

    \vspace{0.5cm}
    \textbf{Strengths:}
    \begin{itemize}
        \item Superior instruction-following capability
        \item Leverages full VLM language understanding
        \item Discrete tokens = stable training
    \end{itemize}

    \vspace{0.5cm}
    \textbf{Weakness:}
    \begin{itemize}
        \item Higher latency due to 27 forward passes
        \item Discretization error from tokenization
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{RDT2-FM: Stage 2}
    \begin{block}{Architecture}
        \textbf{Frozen} Qwen2.5-VL + 400M RDT Action Expert
    \end{block}

    \vspace{0.5cm}
    \textbf{Key Changes from VQ:}
    \begin{itemize}
        \item Replace discrete tokenizer with continuous diffusion
        \item Qwen backbone is frozen (not trained)
        \item Only RDT expert is trained
    \end{itemize}

    \vspace{0.5cm}
    \textbf{Training:}
    \begin{itemize}
        \item Flow-matching loss
        \item 5 denoising steps during inference
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{RDT2-FM: Key Properties}
    \textbf{Inference Process:}
    \begin{itemize}
        \item 1 Qwen forward (extract KV cache)
        \item 5 RDT forwards (denoising steps)
        \item Total: 6 forward passes
    \end{itemize}

    \vspace{0.5cm}
    \textbf{Strengths:}
    \begin{itemize}
        \item No discretization error
        \item Lower latency (6 vs 27 forwards)
        \item Continuous action output
    \end{itemize}

    \vspace{0.5cm}
    \textbf{Variant:}
    \begin{itemize}
        \item \textbf{RDT2-FM-Post}: Adds UR/Franka real robot data
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{RDT2-UltraFast: Stage 3}
    \begin{block}{Architecture}
        One-step diffusion distilled from RDT2-FM
    \end{block}

    \vspace{0.5cm}
    \textbf{Method:}
    \begin{itemize}
        \item Knowledge distillation from RDT2-FM
        \item Maps noise directly to actions in single step
    \end{itemize}

    \vspace{0.5cm}
    \textbf{Inference:}
    \begin{itemize}
        \item 1 Qwen forward + 1 RDT forward = 2 total
        \item Real-time capable ($\sim$100ms)
    \end{itemize}

    \vspace{0.5cm}
    \begin{alertblock}{Status}
        Coming Soon
    \end{alertblock}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Inference Latency Comparison}
    \begin{table}
        \centering
        \renewcommand{\arraystretch}{1.4}
        \begin{tabular}{lcc}
            \toprule
            \textbf{Model}     & \textbf{Forward Passes} & \textbf{Relative Speed} \\
            \midrule
            RDT2-VQ            & 27                      & 1$\times$               \\
            RDT2-FM            & 6                       & $\sim$4.5$\times$       \\
            RDT2-UltraFast     & 2                       & $\sim$13.5$\times$      \\
            \bottomrule
        \end{tabular}
    \end{table}

    \vspace{0.5cm}
    \begin{block}{Note}
        Actual latency depends on hardware and batch size
    \end{block}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{HuggingFace Model Links}
    \textbf{Available Models:}

    \vspace{0.5cm}
    \begin{itemize}
        \item \textbf{RDT2-VQ:}

              \small\texttt{robotics-diffusion-transformer/RDT2-VQ}

              \vspace{0.3cm}
        \item \textbf{RDT2-FM:}

              \small\texttt{robotics-diffusion-transformer/RDT2-FM}

              \vspace{0.3cm}
        \item \textbf{RVQ Tokenizer:}

              \small\texttt{robotics-diffusion-transformer/RVQActionTokenizer}
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Hardware Requirements}
    \begin{table}
        \centering
        \renewcommand{\arraystretch}{1.3}
        \begin{tabular}{lcc}
            \toprule
            \textbf{Task}          & \textbf{VRAM}  & \textbf{Example GPU}   \\
            \midrule
            Inference              & $\sim$16 GB    & RTX 4090               \\
            Fine-tune RDT only     & $\sim$16 GB    & RTX 4090               \\
            Fine-tune LoRA         & $\geq$32 GB    & A100 40GB              \\
            Fine-tune Full         & $\geq$80 GB    & A100 80GB / H100       \\
            \bottomrule
        \end{tabular}
    \end{table}

    \vspace{0.5cm}
    \textbf{Tested OS:} Ubuntu 24.04
\end{frame}
